{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network Architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step1: Lets first import all libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "As we learned in theory part of Siamese Network, that as part of data preprocessing we need to create pairs.\n",
    "1. 1 pair-> similar; y=0\n",
    "2. 1 pair-> dissimilar; y=1\n",
    "\n",
    "Note: We are using contrastive loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2: To preporcess data, and create iterator for model, first create a Dataset Loader Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    '''\n",
    "    Class Dataset:\n",
    "    Input: numpy values\n",
    "    Output: torch variables.\n",
    "    '''\n",
    "    def __init__(self, x0, x1, label):\n",
    "        self.size = label.shape[0] \n",
    "        self.x0 = torch.from_numpy(x0)\n",
    "        self.x1 = torch.from_numpy(x1)\n",
    "        self.label = torch.from_numpy(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x0[index],\n",
    "                self.x1[index],\n",
    "                self.label[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before creating an iterator, lets create pairs, and preprocess images in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairs(data, digit_indices):\n",
    "    x0_data = []\n",
    "    x1_data = []\n",
    "    label = []\n",
    "    n = min([len(digit_indices[d]) for d in range(11)]) - 1\n",
    "    for d in range(11): # for MNIST dataset: as we have 10 digits\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            x0_data.append(data[z1]/255.) # Image Preprocessing Step\n",
    "            x1_data.append(data[z2]/255.) # Image Preprocessing Step\n",
    "            label.append(1)\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            x0_data.append(data[z1]/255.) # Image Preprocessing Step\n",
    "            x1_data.append(data[z2]/255.) # Image Preprocessing Step\n",
    "            label.append(0)\n",
    "\n",
    "    x0_data = np.array(x0_data, dtype=np.float32) #[:10201]\n",
    "#     print (x0_data.shape)\n",
    "    x0_data = x0_data.reshape([-1, 3, 224, 224])\n",
    "    x1_data = np.array(x1_data, dtype=np.float32) #[:10201]\n",
    "    x1_data = x1_data.reshape([-1, 3, 224, 224])\n",
    "    label = np.array(label, dtype=np.int32)\n",
    "#     print (label.shape)\n",
    "    return x0_data, x1_data, label\n",
    "\n",
    "def create_iterator(data, label, batchsize, shuffle=False):\n",
    "#     print (\"max label\", max(label))\n",
    "    digit_indices = [np.where(label == i)[0] for i in range(max(label)+1)]\n",
    "    x0, x1, label = create_pairs(data, digit_indices)\n",
    "    ret = Dataset(x0, x1, label)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### create iterator: returns set of given batchsize for training purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function: Contrastive Loss Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create Loss Function\n",
    "As we know contrastive loss function consists of 2 parts:\n",
    "![contrastive%20Loss.png](Images/contrastiveLoss.png)\n",
    "\n",
    "1. for similar points: (1-y)*(distance_function)^2\n",
    "2. for dissimilar points: y*{max(0,(m-distance_function^2)}\n",
    "\n",
    "Here Distance Function is taken as euclidean distance, also known as root mean square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contrastive_loss_function(x0, x1, y, margin=1.0):\n",
    "    # euclidean distance\n",
    "    diff = x0 - x1\n",
    "    dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "    dist = torch.sqrt(dist_sq)\n",
    "    mdist = margin - dist\n",
    "#     print (mdist)\n",
    "    dist = torch.clamp(mdist, min=0.0)\n",
    "    loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
    "#     print (loss)\n",
    "    loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "#     print (loss, x0.size()[0])\n",
    "#     print (\"next\")\n",
    "    return loss\n",
    "\n",
    "def triplet_loss(positive, negative,anchor, size_average=True, margin=1.0):\n",
    "    distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
    "    distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
    "    losses = F.relu(distance_positive - distance_negative + margin)\n",
    "    return losses.mean() if size_average else losses.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Creating Siamese Network Architecture\n",
    "For this first lets create a class called SiameseNetwork with 2 functions:\n",
    "###### 1. forward_once: In forward_once pass through all layers and returns the output embeddings \n",
    "###### 2. forward: In forward, call forward_once 2 times for the Input pair given, and returns the embeddings obtained\n",
    "\n",
    "\n",
    "As discussed in theory part of Siamese Network, we share parameters of twins, so we don't need to create explicitly both brances, we can just create one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize=8\n",
    "import copy\n",
    "# [N, C, W, H] \n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 20, kernel_size=5, padding=1),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(20, 50, kernel_size=5, padding=1),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=1),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(34312, 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(8,10),\n",
    "            nn.Linear(10, 2))\n",
    "        global vgg_bottleneck\n",
    "        vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "#         print (x.shape)\n",
    "        x_= copy.deepcopy(x)\n",
    "        x_= x_.data.numpy()\n",
    "        x_= x_.reshape(len(x_),224,224,3)\n",
    "        train_vgg_bf = vgg_bottleneck.predict(x_, batch_size=8, verbose=0)\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        b = torch.tensor(train_vgg_bf)\n",
    "        b = b.view(b.size(0), -1)\n",
    "\n",
    "        output = torch.cat([output, b], dim=1)\n",
    "#         print (output.shape) #torch.Size([8, 140450])\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1310, 1, 224, 224, 3)\n",
      "(562, 1, 224, 224, 3)\n",
      "(1310,)\n",
      "(562,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "def extract_features(path):\n",
    "    directory_lists=os.listdir(path)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    count=0\n",
    "    if ('.DS_Store' in directory_lists):\n",
    "            directory_lists.remove('.DS_Store')\n",
    "    for d in directory_lists:\n",
    "        nest=os.listdir(path+\"/\"+d)\n",
    "        if ('.DS_Store' in nest):\n",
    "            nest.remove('.DS_Store')\n",
    "        for f in nest:\n",
    "            img = image.load_img(path+\"/\"+d+\"/\"+f, target_size=(224, 224))\n",
    "            img_data = image.img_to_array(img)\n",
    "            img_data = preprocess_input(img_data)\n",
    "            img_data = np.expand_dims(img_data, axis=0)\n",
    "            X.append(img_data)\n",
    "            Y.append(count)\n",
    "        count+=1\n",
    "    X=np.array(X)\n",
    "    y=np.array(Y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)         \n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "X_train, X_test, y_train, y_test = extract_features(\"./Data/train/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We created an iterator above, here we will use it to create training and test set iterators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter = create_iterator(X_train,y_train,batchsize)\n",
    "test_iter = create_iterator(X_test,y_test,batchsize)\n",
    "\n",
    "# call model\n",
    "model = SiameseNetwork()\n",
    "# model = torch.load('./siamese.pth')\n",
    "# model.eval()\n",
    "learning_rate = 0.001 # learning rate for optimization\n",
    "momentum = 0.9 # momentum\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion =  contrastive_loss_function\n",
    "#contrastive_loss_function # we will use contrastive loss function as defined above\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=50, verbose=True)\n",
    "# creating a train loader, and a test loader.\n",
    "train_loader = torch.utils.data.DataLoader(train_iter,batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_iter,batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Train our Model !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Train Model for certain number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 0.909582\n",
      "Epoch: 1 \tLoss: 0.694766\n",
      "Epoch: 2 \tLoss: 0.655927\n",
      "Epoch: 3 \tLoss: 0.642793\n",
      "Epoch: 4 \tLoss: 0.612342\n",
      "Epoch: 5 \tLoss: 0.602218\n",
      "Epoch: 6 \tLoss: 0.593924\n",
      "Epoch: 7 \tLoss: 0.565308\n",
      "Epoch: 8 \tLoss: 0.555189\n",
      "Epoch: 9 \tLoss: 0.560129\n",
      "Epoch: 10 \tLoss: 0.538603\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 11 \tLoss: 0.526148\n",
      "Epoch: 12 \tLoss: 0.505046\n",
      "Epoch: 13 \tLoss: 0.492801\n",
      "Epoch: 14 \tLoss: 0.490949\n",
      "Epoch: 15 \tLoss: 0.489370\n",
      "Epoch: 16 \tLoss: 0.487194\n",
      "Epoch: 17 \tLoss: 0.487279\n",
      "Epoch: 18 \tLoss: 0.487545\n",
      "Epoch: 19 \tLoss: 0.486376\n",
      "Epoch: 20 \tLoss: 0.479335\n",
      "Epoch: 21 \tLoss: 0.478816\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch: 22 \tLoss: 0.476945\n",
      "Epoch: 23 \tLoss: 0.474335\n",
      "Epoch: 24 \tLoss: 0.475412\n",
      "Epoch: 25 \tLoss: 0.474042\n",
      "Epoch: 26 \tLoss: 0.474406\n",
      "Epoch: 27 \tLoss: 0.473888\n",
      "Epoch: 28 \tLoss: 0.476419\n",
      "Epoch: 29 \tLoss: 0.477092\n",
      "Epoch: 30 \tLoss: 0.472870\n",
      "Epoch: 31 \tLoss: 0.474559\n",
      "Epoch: 32 \tLoss: 0.476576\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch: 33 \tLoss: 0.474348\n",
      "Epoch: 34 \tLoss: 0.472414\n",
      "Epoch: 35 \tLoss: 0.474940\n",
      "Epoch: 36 \tLoss: 0.472105\n",
      "Epoch: 37 \tLoss: 0.473381\n",
      "Epoch: 38 \tLoss: 0.471820\n",
      "Epoch: 39 \tLoss: 0.474561\n",
      "Epoch: 40 \tLoss: 0.471055\n",
      "Epoch: 41 \tLoss: 0.471175\n",
      "Epoch: 42 \tLoss: 0.472830\n",
      "Epoch: 43 \tLoss: 0.471774\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch: 44 \tLoss: 0.473131\n",
      "Epoch: 45 \tLoss: 0.471831\n",
      "Epoch: 46 \tLoss: 0.472486\n",
      "Epoch: 47 \tLoss: 0.472047\n",
      "Epoch: 48 \tLoss: 0.473905\n",
      "Epoch: 49 \tLoss: 0.473178\n",
      "Epoch: 50 \tLoss: 0.471873\n",
      "Epoch: 51 \tLoss: 0.473530\n",
      "Epoch: 52 \tLoss: 0.472935\n",
      "Epoch: 53 \tLoss: 0.473481\n",
      "Epoch: 54 \tLoss: 0.473792\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch: 55 \tLoss: 0.472690\n",
      "Epoch: 56 \tLoss: 0.470913\n",
      "Epoch: 57 \tLoss: 0.471706\n",
      "Epoch: 58 \tLoss: 0.472795\n",
      "Epoch: 59 \tLoss: 0.472778\n",
      "Epoch: 60 \tLoss: 0.472955\n",
      "Epoch: 61 \tLoss: 0.475019\n",
      "Epoch: 62 \tLoss: 0.470387\n",
      "Epoch: 63 \tLoss: 0.475949\n",
      "Epoch: 64 \tLoss: 0.473084\n",
      "Epoch: 65 \tLoss: 0.473633\n",
      "Epoch: 66 \tLoss: 0.470881\n",
      "Epoch: 67 \tLoss: 0.474453\n",
      "Epoch: 68 \tLoss: 0.473616\n",
      "Epoch: 69 \tLoss: 0.473833\n",
      "Epoch: 70 \tLoss: 0.472977\n",
      "Epoch: 71 \tLoss: 0.473737\n",
      "Epoch: 72 \tLoss: 0.473825\n",
      "Epoch: 73 \tLoss: 0.471670\n",
      "Epoch: 74 \tLoss: 0.471848\n",
      "Epoch: 75 \tLoss: 0.471270\n",
      "Epoch: 76 \tLoss: 0.471398\n",
      "Epoch: 77 \tLoss: 0.472891\n",
      "Epoch: 78 \tLoss: 0.475212\n",
      "Epoch: 79 \tLoss: 0.472517\n",
      "Epoch: 80 \tLoss: 0.472158\n",
      "Epoch: 81 \tLoss: 0.471490\n",
      "Epoch: 82 \tLoss: 0.474557\n",
      "Epoch: 83 \tLoss: 0.472470\n",
      "Epoch: 84 \tLoss: 0.471491\n",
      "Epoch: 85 \tLoss: 0.471310\n",
      "Epoch: 86 \tLoss: 0.473189\n",
      "Epoch: 87 \tLoss: 0.473870\n",
      "Epoch: 88 \tLoss: 0.472000\n",
      "Epoch: 89 \tLoss: 0.475781\n",
      "Epoch: 90 \tLoss: 0.472705\n",
      "Epoch: 91 \tLoss: 0.471363\n",
      "Epoch: 92 \tLoss: 0.472731\n",
      "Epoch: 93 \tLoss: 0.471590\n",
      "Epoch: 94 \tLoss: 0.472586\n",
      "Epoch: 95 \tLoss: 0.473293\n",
      "Epoch: 96 \tLoss: 0.472657\n",
      "Epoch: 97 \tLoss: 0.474741\n",
      "Epoch: 98 \tLoss: 0.473397\n",
      "Epoch: 99 \tLoss: 0.471695\n",
      "Epoch: 100 \tLoss: 0.472310\n",
      "Epoch: 101 \tLoss: 0.471822\n",
      "Epoch: 102 \tLoss: 0.473362\n",
      "Epoch: 103 \tLoss: 0.473509\n",
      "Epoch: 104 \tLoss: 0.472866\n",
      "Epoch: 105 \tLoss: 0.471250\n",
      "Epoch: 106 \tLoss: 0.473213\n",
      "Epoch: 107 \tLoss: 0.473727\n",
      "Epoch: 108 \tLoss: 0.472931\n",
      "Epoch: 109 \tLoss: 0.470199\n",
      "Epoch: 110 \tLoss: 0.471172\n",
      "Epoch: 111 \tLoss: 0.470762\n",
      "Epoch: 112 \tLoss: 0.473740\n",
      "Epoch: 113 \tLoss: 0.472161\n",
      "Epoch: 114 \tLoss: 0.473374\n",
      "Epoch: 115 \tLoss: 0.470989\n",
      "Epoch: 116 \tLoss: 0.473831\n",
      "Epoch: 117 \tLoss: 0.473268\n",
      "Epoch: 118 \tLoss: 0.472504\n",
      "Epoch: 119 \tLoss: 0.473560\n",
      "Epoch: 120 \tLoss: 0.474168\n",
      "Epoch: 121 \tLoss: 0.472507\n",
      "Epoch: 122 \tLoss: 0.471867\n",
      "Epoch: 123 \tLoss: 0.473383\n",
      "Epoch: 124 \tLoss: 0.472546\n",
      "Epoch: 125 \tLoss: 0.472703\n",
      "Epoch: 126 \tLoss: 0.472623\n",
      "Epoch: 127 \tLoss: 0.474961\n",
      "Epoch: 128 \tLoss: 0.474462\n",
      "Epoch: 129 \tLoss: 0.472714\n",
      "Epoch: 130 \tLoss: 0.475924\n",
      "Epoch: 131 \tLoss: 0.476070\n",
      "Epoch: 132 \tLoss: 0.472556\n",
      "Epoch: 133 \tLoss: 0.471420\n",
      "Epoch: 134 \tLoss: 0.473324\n",
      "Epoch: 135 \tLoss: 0.471424\n",
      "Epoch: 136 \tLoss: 0.472622\n",
      "Epoch: 137 \tLoss: 0.472390\n",
      "Epoch: 138 \tLoss: 0.472419\n",
      "Epoch: 139 \tLoss: 0.472172\n",
      "Epoch: 140 \tLoss: 0.471028\n",
      "Epoch: 141 \tLoss: 0.473143\n",
      "Epoch: 142 \tLoss: 0.471316\n",
      "Epoch: 143 \tLoss: 0.472574\n",
      "Epoch: 144 \tLoss: 0.472606\n",
      "Epoch: 145 \tLoss: 0.473541\n",
      "Epoch: 146 \tLoss: 0.474333\n",
      "Epoch: 147 \tLoss: 0.472665\n",
      "Epoch: 148 \tLoss: 0.472365\n",
      "Epoch: 149 \tLoss: 0.473491\n",
      "Epoch: 150 \tLoss: 0.471710\n",
      "Epoch: 151 \tLoss: 0.471786\n",
      "Epoch: 152 \tLoss: 0.472175\n",
      "Epoch: 153 \tLoss: 0.470854\n",
      "Epoch: 154 \tLoss: 0.472101\n",
      "Epoch: 155 \tLoss: 0.471362\n",
      "Epoch: 156 \tLoss: 0.474414\n",
      "Epoch: 157 \tLoss: 0.472194\n",
      "Epoch: 158 \tLoss: 0.471414\n",
      "Epoch: 159 \tLoss: 0.471340\n",
      "Epoch: 160 \tLoss: 0.472811\n",
      "Epoch: 161 \tLoss: 0.474153\n",
      "Epoch: 162 \tLoss: 0.475835\n",
      "Epoch: 163 \tLoss: 0.474816\n",
      "Epoch: 164 \tLoss: 0.471158\n",
      "Epoch: 165 \tLoss: 0.473723\n",
      "Epoch: 166 \tLoss: 0.474752\n",
      "Epoch: 167 \tLoss: 0.473919\n",
      "Epoch: 168 \tLoss: 0.472236\n",
      "Epoch: 169 \tLoss: 0.472034\n",
      "Epoch: 170 \tLoss: 0.472158\n",
      "Epoch: 171 \tLoss: 0.473540\n",
      "Epoch: 172 \tLoss: 0.474248\n",
      "Epoch: 173 \tLoss: 0.474524\n",
      "Epoch: 174 \tLoss: 0.474295\n",
      "Epoch: 175 \tLoss: 0.473651\n",
      "Epoch: 176 \tLoss: 0.472107\n",
      "Epoch: 177 \tLoss: 0.470876\n",
      "Epoch: 178 \tLoss: 0.473608\n",
      "Epoch: 179 \tLoss: 0.470684\n",
      "Epoch: 180 \tLoss: 0.470517\n",
      "Epoch: 181 \tLoss: 0.470934\n",
      "Epoch: 182 \tLoss: 0.473289\n",
      "Epoch: 183 \tLoss: 0.470520\n",
      "Epoch: 184 \tLoss: 0.471442\n",
      "Epoch: 185 \tLoss: 0.473677\n",
      "Epoch: 186 \tLoss: 0.472486\n",
      "Epoch: 187 \tLoss: 0.472555\n",
      "Epoch: 188 \tLoss: 0.473883\n",
      "Epoch: 189 \tLoss: 0.472381\n",
      "Epoch: 190 \tLoss: 0.471707\n",
      "Epoch: 191 \tLoss: 0.476905\n",
      "Epoch: 192 \tLoss: 0.472732\n",
      "Epoch: 193 \tLoss: 0.472570\n",
      "Epoch: 194 \tLoss: 0.471356\n",
      "Epoch: 195 \tLoss: 0.477694\n",
      "Epoch: 196 \tLoss: 0.471629\n",
      "Epoch: 197 \tLoss: 0.473632\n",
      "Epoch: 198 \tLoss: 0.470761\n",
      "Epoch: 199 \tLoss: 0.471991\n",
      "Epoch: 200 \tLoss: 0.474219\n",
      "Epoch: 201 \tLoss: 0.471367\n",
      "Epoch: 202 \tLoss: 0.470758\n",
      "Epoch: 203 \tLoss: 0.472626\n",
      "Epoch: 204 \tLoss: 0.473927\n",
      "Epoch: 205 \tLoss: 0.471707\n",
      "Epoch: 206 \tLoss: 0.474154\n",
      "Epoch: 207 \tLoss: 0.474735\n",
      "Epoch: 208 \tLoss: 0.474742\n",
      "Epoch: 209 \tLoss: 0.472669\n",
      "Epoch: 210 \tLoss: 0.473971\n",
      "Epoch: 211 \tLoss: 0.472981\n",
      "Epoch: 212 \tLoss: 0.472048\n",
      "Epoch: 213 \tLoss: 0.472090\n",
      "Epoch: 214 \tLoss: 0.470606\n",
      "Epoch: 215 \tLoss: 0.475205\n",
      "Epoch: 216 \tLoss: 0.472264\n",
      "Epoch: 217 \tLoss: 0.471987\n",
      "Epoch: 218 \tLoss: 0.472016\n",
      "Epoch: 219 \tLoss: 0.472410\n",
      "Epoch: 220 \tLoss: 0.473424\n",
      "Epoch: 221 \tLoss: 0.472397\n",
      "Epoch: 222 \tLoss: 0.472932\n",
      "Epoch: 223 \tLoss: 0.472010\n",
      "Epoch: 224 \tLoss: 0.472317\n",
      "Epoch: 225 \tLoss: 0.474359\n",
      "Epoch: 226 \tLoss: 0.470302\n",
      "Epoch: 227 \tLoss: 0.474346\n",
      "Epoch: 228 \tLoss: 0.474799\n",
      "Epoch: 229 \tLoss: 0.473496\n",
      "Epoch: 230 \tLoss: 0.477814\n",
      "Epoch: 231 \tLoss: 0.470970\n",
      "Epoch: 232 \tLoss: 0.473623\n",
      "Epoch: 233 \tLoss: 0.472560\n",
      "Epoch: 234 \tLoss: 0.471917\n",
      "Epoch: 235 \tLoss: 0.472291\n",
      "Epoch: 236 \tLoss: 0.474491\n",
      "Epoch: 237 \tLoss: 0.473324\n",
      "Epoch: 238 \tLoss: 0.473942\n",
      "Epoch: 239 \tLoss: 0.471297\n",
      "Epoch: 240 \tLoss: 0.471503\n",
      "Epoch: 241 \tLoss: 0.473437\n",
      "Epoch: 242 \tLoss: 0.472306\n",
      "Epoch: 243 \tLoss: 0.472570\n",
      "Epoch: 244 \tLoss: 0.474623\n",
      "Epoch: 245 \tLoss: 0.473955\n",
      "Epoch: 246 \tLoss: 0.470455\n",
      "Epoch: 247 \tLoss: 0.472792\n",
      "Epoch: 248 \tLoss: 0.473668\n",
      "Epoch: 249 \tLoss: 0.473771\n",
      "Epoch: 250 \tLoss: 0.473369\n",
      "Epoch: 251 \tLoss: 0.470706\n",
      "Epoch: 252 \tLoss: 0.471084\n",
      "Epoch: 253 \tLoss: 0.474108\n",
      "Epoch: 254 \tLoss: 0.471356\n",
      "Epoch: 255 \tLoss: 0.475199\n",
      "Epoch: 256 \tLoss: 0.472320\n",
      "Epoch: 257 \tLoss: 0.472827\n",
      "Epoch: 258 \tLoss: 0.471004\n",
      "Epoch: 259 \tLoss: 0.473529\n",
      "Epoch: 260 \tLoss: 0.473655\n",
      "Epoch: 261 \tLoss: 0.471387\n",
      "Epoch: 262 \tLoss: 0.471126\n",
      "Epoch: 263 \tLoss: 0.473460\n",
      "Epoch: 264 \tLoss: 0.473289\n",
      "Epoch: 265 \tLoss: 0.474622\n",
      "Epoch: 266 \tLoss: 0.470186\n",
      "Epoch: 267 \tLoss: 0.470833\n",
      "Epoch: 268 \tLoss: 0.470579\n",
      "Epoch: 269 \tLoss: 0.471257\n",
      "Epoch: 270 \tLoss: 0.471253\n",
      "Epoch: 271 \tLoss: 0.472598\n",
      "Epoch: 272 \tLoss: 0.470826\n",
      "Epoch: 273 \tLoss: 0.471712\n",
      "Epoch: 274 \tLoss: 0.471238\n",
      "Epoch: 275 \tLoss: 0.471724\n",
      "Epoch: 276 \tLoss: 0.475748\n",
      "Epoch: 277 \tLoss: 0.472970\n",
      "Epoch: 278 \tLoss: 0.472018\n",
      "Epoch: 279 \tLoss: 0.471909\n",
      "Epoch: 280 \tLoss: 0.474279\n",
      "Epoch: 281 \tLoss: 0.473045\n",
      "Epoch: 282 \tLoss: 0.473851\n",
      "Epoch: 283 \tLoss: 0.472491\n",
      "Epoch: 284 \tLoss: 0.473412\n",
      "Epoch: 285 \tLoss: 0.472906\n",
      "Epoch: 286 \tLoss: 0.474034\n",
      "Epoch: 287 \tLoss: 0.473283\n",
      "Epoch: 288 \tLoss: 0.472698\n",
      "Epoch: 289 \tLoss: 0.472569\n",
      "Epoch: 290 \tLoss: 0.473026\n",
      "Epoch: 291 \tLoss: 0.473629\n",
      "Epoch: 292 \tLoss: 0.470438\n",
      "Epoch: 293 \tLoss: 0.472599\n",
      "Epoch: 294 \tLoss: 0.471701\n",
      "Epoch: 295 \tLoss: 0.474189\n",
      "Epoch: 296 \tLoss: 0.472008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 297 \tLoss: 0.471400\n",
      "Epoch: 298 \tLoss: 0.473667\n",
      "Epoch: 299 \tLoss: 0.472555\n",
      "Epoch: 300 \tLoss: 0.473114\n",
      "Epoch: 301 \tLoss: 0.472023\n",
      "Epoch: 302 \tLoss: 0.473164\n",
      "Epoch: 303 \tLoss: 0.472526\n",
      "Epoch: 304 \tLoss: 0.472077\n",
      "Epoch: 305 \tLoss: 0.473397\n",
      "Epoch: 306 \tLoss: 0.473392\n",
      "Epoch: 307 \tLoss: 0.473292\n",
      "Epoch: 308 \tLoss: 0.471774\n",
      "Epoch: 309 \tLoss: 0.472693\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3e82d847c072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a399481e7d80>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a399481e7d80>\u001b[0m in \u001b[0;36mforward_once\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_vgg_bf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_bottleneck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project09/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/opt/anaconda3/envs/project09/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (x0, x1, labels) in enumerate(train_loader):\n",
    "        labels = labels.float()\n",
    "        x0, x1, labels = Variable(x0), Variable(x1), Variable(labels)\n",
    "        output1, output2 = model.forward(x0, x1)\n",
    "        loss = criterion(output1, output2, labels)\n",
    "        train_loss.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step(epoch)\n",
    "    print('Epoch: {} \\tLoss: {:.6f}'.format(epoch, total_loss*1.0/batchsize))\n",
    "    if epoch%50==0:\n",
    "        torch.save(model, './SiameseModified-epoch-%s.pth' % epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Visualize our Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step5: Lets Create all functions for plotting embeddings and loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss Function Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(train_loss,name=\"train_loss.png\"):\n",
    "    plt.plot(train_loss, label=\"train loss\")\n",
    "    plt.legend()\n",
    "plot_loss(train_loss)\n",
    "def plot_mnist(numpy_all, numpy_labels,name=\"./embeddings_plot.png\"):\n",
    "        c = ['#ff0000', '#ffff00', '#00ff00', '#00ffff', '#0000ff',\n",
    "             '#ff00ff', '#990000', '#999900', '#009900', '#009999', '#000fff']\n",
    "        for i in range(0,11):\n",
    "            f = numpy_all[np.where(numpy_labels == i)]\n",
    "#             print (f)\n",
    "            plt.plot(f[:, 0], f[:, 1], '.', c=c[i])\n",
    "        plt.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "        plt.savefig(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting test-set Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "X_test = X_test/255.\n",
    "y_test = np.array(y_test, dtype=np.int32)\n",
    "# print (y_test)\n",
    "def test_model(model):\n",
    "        model.eval()\n",
    "        all_ = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, 562):\n",
    "                x = Variable(torch.tensor(X_test[i].reshape([-1, 1, 224, 224])))\n",
    "#                 print (\"y_tes is\", y_test[i])\n",
    "                y_t = np.array(y_test[i], dtype=np.int32)\n",
    "#                 print (\"y_t is\", y_t)\n",
    "                y = Variable(torch.tensor(y_t))\n",
    "#                 print (\"labels are\", y)\n",
    "                output = model.forward_once(x)\n",
    "                all_.extend(output.data.cpu().numpy().tolist())\n",
    "                all_labels.append(y.data.cpu().numpy().tolist())\n",
    "\n",
    "        numpy_all = np.array(all_)\n",
    "        numpy_labels = np.array(all_labels)\n",
    "#         print (numpy_labels)\n",
    "        return numpy_all, numpy_labels\n",
    "\n",
    "def testing_plots(model):\n",
    "        dict_pickle={}\n",
    "#         print (test_model(model))\n",
    "        numpy_all, numpy_labels = test_model(model)\n",
    "        dict_pickle[\"numpy_all\"]=numpy_all\n",
    "        dict_pickle[\"numpy_labels\"]=numpy_labels\n",
    "        clusterer = KMeans(n_clusters=11)\n",
    "        preds = clusterer.fit_predict(numpy_all)\n",
    "        centers = clusterer.cluster_centers_\n",
    "        score = silhouette_score(numpy_all, preds)\n",
    "        print (score)\n",
    "        plot_mnist(numpy_all, numpy_labels)\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 5, 5\n",
    "testing_plots(model)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
