{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning: Sugarcane disease classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Repository consists of using Transfer Learning Method to detect types of Disease Sugarcane Plant can have.\n",
    "Disease have following categories:\n",
    "1. grassy shoot\n",
    "2. leaf spot\n",
    "3. nitrogen\n",
    "4. orange rust\n",
    "5. pyrilla\n",
    "6. redrot\n",
    "7. smut\n",
    "8. wholly aphid\n",
    "9. wilt\n",
    "10. yellow leaf disease\n",
    "11. leaf scald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/anaconda3/envs/project09/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from keras)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE=224\n",
    "POOLING='avg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Images, and Load them as Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def pil2numpy(img: Image = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert an HxW pixels RGB Image into an HxWx3 numpy ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    if img is None:\n",
    "        print (\"None\")\n",
    "        img = Image.open('amsterdam_190x150.jpg')\n",
    "\n",
    "    np_array = np.asarray(img)\n",
    "    return np_array\n",
    "\n",
    "def numpy2pil(np_array: np.ndarray) -> Image:\n",
    "    \"\"\"\n",
    "    Convert an HxWx3 numpy array into an RGB Image\n",
    "    \"\"\"\n",
    "\n",
    "    assert_msg = 'Input shall be a HxWx3 ndarray'\n",
    "    assert isinstance(np_array, np.ndarray), assert_msg\n",
    "    assert len(np_array.shape) == 3, assert_msg\n",
    "    assert np_array.shape[2] == 3, assert_msg\n",
    "\n",
    "    img = Image.fromarray(np_array, 'RGB')\n",
    "    return img\n",
    "\n",
    "def extract_features(path):\n",
    "    directory_lists=os.listdir(path)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    count=0\n",
    "    plot_images = []\n",
    "    if ('.DS_Store' in directory_lists):\n",
    "            directory_lists.remove('.DS_Store')\n",
    "    for d in directory_lists:\n",
    "        nest=os.listdir(path+\"/\"+d)\n",
    "        if ('.DS_Store' in nest):\n",
    "            nest.remove('.DS_Store')\n",
    "        print (d)\n",
    "        print (len(nest))\n",
    "        for f in nest:\n",
    "            img = image.load_img(path+\"/\"+d+\"/\"+f, target_size=(224, 224))\n",
    "            img_data = image.img_to_array(img)\n",
    "            img_data = preprocess_input(img_data)\n",
    "            X.append(img_data)\n",
    "            Y.append(count)\n",
    "#         plot_images.append(mpimg.imread(path+d+\"/\"+f))\n",
    "        count+=1\n",
    "    X=np.array(X)\n",
    "    y=np.array(Y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "# X_train, X_test, y_train, y_test, plot_images = extract_features(\"./data_2/\")\n",
    "\n",
    "# print (plot_images)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "# datagen = ImageDataGenerator(rotation_range=20, \n",
    "#                              zoom_range=0.15,\n",
    "#                              width_shift_range=0.2,\n",
    "#                              height_shift_range=0.2,\n",
    "#                              shear_range=0.15,\n",
    "#                              horizontal_flip=True,\n",
    "#                              fill_mode=\"nearest\")\n",
    "# path = \"./augmented/\"\n",
    "# directory_lists=os.listdir(\"./augmented/\")\n",
    "# for d in directory_lists:\n",
    "#         nest=os.listdir(path+\"/\"+d)\n",
    "#         if ('.DS_Store' in nest):\n",
    "#             nest.remove('.DS_Store')\n",
    "#         if len(nest)<20:\n",
    "#             for f in nest:\n",
    "#                 img = load_img(path+\"/\"+d+\"/\"+f)  \n",
    "#                 x = img_to_array(img) \n",
    "#                 # Reshape the input image \n",
    "#                 x = x.reshape((1, ) + x.shape)  \n",
    "#                 i = 0\n",
    "#                 # generate 5 new augmented images \n",
    "#                 for batch in datagen.flow(x, batch_size = 1, \n",
    "#                                   save_to_dir = path+\"/\"+d+\"/\",  \n",
    "#                                   save_prefix ='augmentation', save_format ='jpeg'):\n",
    "#                     i += 1\n",
    "#                     if i > 5: \n",
    "#                         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are using Transfer Learning using features extracted from VGG16, and Xception model trained on Image Net, we are just extracting BottleNeck Features, as we just want to learn generic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import f1_score\n",
    "def forward_pass_Resnt():\n",
    "        X_train, X_test, y_train, y_test = extract_features(\"./no_aug_data/\")\n",
    "        print (X_train.shape)\n",
    "        vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "        train_vgg_bf = vgg_bottleneck.predict(X_train, batch_size=32, verbose=1)\n",
    "        valid_vgg_bf = vgg_bottleneck.predict(X_test, batch_size=32, verbose=1)\n",
    "        \n",
    "#         xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "#         train_x_bf = xception_bottleneck.predict(X_train, batch_size=32, verbose=1)\n",
    "#         valid_x_bf = xception_bottleneck.predict(X_test, batch_size=32, verbose=1)\n",
    "        \n",
    "#         X = np.hstack([train_x_bf, train_vgg_bf])\n",
    "#         V = np.hstack([valid_x_bf, valid_vgg_bf])\n",
    "# #         print (X.shape)\n",
    "        logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=147)\n",
    "        logreg.fit(train_vgg_bf, y_train)\n",
    "        valid_probs = logreg.predict_proba(valid_vgg_bf)\n",
    "        valid_preds = logreg.predict(valid_vgg_bf)\n",
    "#         print (\"validation probability: {}\".format(valid_probs))\n",
    "#         print (\"validation_predictions: {}\".format(valid_preds))\n",
    "#         print (\"Log Loss of Test Set:{}\".format(log_loss(y_test, valid_probs)))\n",
    "        print (\"Accuracy:{}\".format(accuracy_score(y_test, valid_preds)))\n",
    "        print (\"F1 Score\",f1_score(y_test, valid_preds, average='macro'))\n",
    "#         numpy_all = logreg.coef_\n",
    "#         print (numpy_all)\n",
    "#         clusterer = KMeans(n_clusters=11)\n",
    "#         preds = clusterer.fit_predict(X)\n",
    "#         centers = clusterer.cluster_centers_\n",
    "#         score = silhouette_score(X, preds)\n",
    "#         print (\"Sillouette Score\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyrilla\n",
      "16\n",
      "wholly_aphid\n",
      "33\n",
      "redrot\n",
      "29\n",
      "wilt\n",
      "22\n",
      "grassy_shoot\n",
      "23\n",
      "nitrogen\n",
      "17\n",
      "leaf_spot\n",
      "4\n",
      "leafscald\n",
      "2\n",
      "orange_rust\n",
      "3\n",
      "smut\n",
      "4\n",
      "yellow_leaf_disease\n",
      "2\n",
      "(108, 224, 224, 3)\n",
      "108/108 [==============================] - 12s 115ms/step\n",
      "47/47 [==============================] - 5s 117ms/step\n",
      "Accuracy:0.574468085106383\n",
      "F1 Score 0.39048359048359044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/project09/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "forward_pass_Resnt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
